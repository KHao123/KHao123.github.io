---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a Ph.D. student in AI Thrust, HKUST(GZ), supervised by Prof. <a href='https://www.yingcong.me/'>Yingcong Chen</a> and Prof. <a href='https://cislab.hkust-gz.edu.cn/members/zeyu-wang/'>Zeyu Wang</a>. I did my master(2020-2022) at the Sun Yat-sen University, where I was advised by Prof. <a href="http://www.isee-ai.cn/~wangruixuan/">Ruixuan Wang</a> and Prof. <a href="http://www.isee-ai.cn/~zhwshi/">Wei-Shi Zheng</a>. I did my bachelor(2016-2020) at the Jinan University, majoring in computer science.

My primary research interests includes 3D reconstruction/generatio, bio-inspired vision, machine learning and medical image analysis. If you are also interested in these fields, please feel free to email me for further discussion on my works.

Recently, I am investgating on 3D/4D scene reconstruction and generation.




# üî• News
- *2024.09*: &nbsp;üéâüéâ One paper is accepted by NeurIPS2024. 
- *2024.03*: &nbsp;üéâüéâ One paper is accepted by CVPR2024 Oral. 
- *2023.09*: &nbsp;I join AI Thrust, Info Hub in HKUST(GZ) as a Ph.D. student.

# üìù Publications 
## üëÅÔ∏è Bio-inspired Vision

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024</div><img src='images/lase-e2v_overview.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LaSe-E2V: Towards Language-guided Semantic-Aware Event-to-Video Reconstruction](https://openreview.net/pdf?id=3ilqQHBWTf) \\

**Kanghao Chen**, Hangyu Li, JiaZhou Zhou, Zeyu Wang, Lin Wang

[**Project**](https://vlislab22.github.io/LaSe-E2V/) 
<!-- <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
<!-- - Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->
</div>
</div>



- <div class="badge">CVPR 2024</div><span style="color:red">(Oral)</span> [Towards Robust Event-guided Low-Light Image Enhancement: A Large-Scale Real-World Event-Image Dataset and Novel Approach](https://openaccess.thecvf.com/content/CVPR2024/papers/Liang_Towards_Robust_Event-guided_Low-Light_Image_Enhancement_A_Large-Scale_Real-World_Event-Image_CVPR_2024_paper.pdf), Guoqiang Liang, **Kanghao Chen**, Hangyu Li, Yunfan Lu, Lin Wang.
- <div class="badge">arXiv</div> [EvLight++: Low-Light Video Enhancement with an Event Camera: A Large-Scale Real-World Dataset, Novel Method, and More](https://arxiv.org/abs/2408.16254), **Kanghao Chen**, Guoqiang Liang, Hangyu Li, Yunfan Lu, Lin Wang.
- <div class="badge">arXiv</div> [ExFMan: Rendering 3D Dynamic Humans with Hybrid Monocular Blurry Frames and Events](https://arxiv.org/abs/2409.14103), **Kanghao Chen**, Zeyu Wang, Lin Wang. 




## ü§ñ Machine Learning
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/imbalance_2021.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
[Alleviating data imbalance issue with perturbed input during inference](https://link.springer.com/chapter/10.1007/978-3-030-87240-3_39) \\

**Kanghao Chen**, Yifan Mao, Huijuan Lu, Chenghua Zeng, Ruixuan Wang, Wei-Shi Zheng


</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JBHI 2023</div><img src='images/pcct.jpg' alt="sym" width="70%"></div></div>
<div class='paper-box-text' markdown="1">
[PCCT: Progressive class-center triplet loss for imbalanced medical image classification](https://ieeexplore.ieee.org/abstract/document/10026863) \\

**Kanghao Chen**, Weixian Lei, Shen Zhao, Wei-Shi Zheng, Ruixuan Wang


</div>
</div>

- <div class="badge">ICME 2022</div> [Improving Class Balancing at Both Feature Extractor and Classifier Head](https://ieeexplore.ieee.org/abstract/document/9860019), **Kanghao Chen**, Huijuan Lu, Ruixuan Wang, Wei-Shi Zheng.


- <div class="badge">CAC 2024</div> [Adaptively Integrated Knowledge Distillation and Prediction Uncertainty for Continual Learning](https://ieeexplore.ieee.org/abstract/document/10450726/), **Kanghao Chen**, Sijia Lin, Jianguo Zhang, Wei-Shi Zheng, Ruixuan Wang.
- <div class="badge">BIBM 2023</div> [Expert with outlier exposure for continual learning of new diseases](https://ieeexplore.ieee.org/abstract/document/9995352), Zhengjing Xu, **Kanghao Chen**, Wei-Shi Zheng, Zhijun Tan, Xiaobo Yang, Ruixuan Wang.
- <div class="badge">IntelliSys</div> [Synthetic minority with cutmix for imbalanced image classification](https://link.springer.com/chapter/10.1007/978-3-031-16078-3_37), Chenghua Zeng, Huijuan Lu, **Kanghao Chen**, Ruixuan Wang, Jun Tao



## ü©ª Medical Image Analysis
- <div class="badge">JOR spine</div> [Automatic Lenke classification of adolescent idiopathic scoliosis with deep learning](https://onlinelibrary.wiley.com/doi/full/10.1002/jsp2.1327), Baolin Zhang, **Kanghao Chen**, Haodong Yuan, Zhiheng Liao, Taifeng Zhou, Weiming Guo, Shen Zhao, Ruixuan Wang, Peiqiang Su

# üéñ Honors and Awards
- *2019-2020* National Scholarship 
- *2016-2017* First Prize School Scholarship

# üìñ Educations
- *2023.09 - now*, Ph.D., AI, Hong Kong University of Science and Technology (Guangzhou). 
- *2020.09 - 2022.06*, Master of Engineering, Computer Technology, Sun Yat-sen University.
- *2016.09 - 2020.06*, Bachelor of Engineering, Computer Science and Technology, Jinan University, Guangzhou 

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Research Experience
- *2022.07 - 2023.05*, Algorithm Researcher, [SenseTime](https://www.sensetime.com/cn), China.
- *2021.07 - 2021.09*, Research Intern, [Netease](https://www.neteasegames.com/), China.